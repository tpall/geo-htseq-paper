container: "docker://rstatstartu/rstanverse:latest"

localrules:
    all,
    staple,

FIGS=list(range(1, 7))

rule all:
    input:
        "results/supporting_information.pdf",
        "results/main.pdf",
        "results/pall_et_al.pdf",
        expand("figures/Fig{n}.tiff", n=FIGS),
        "results/sequencing_metadata.csv",


rule download:
    output:
        "results/geo-htseq.tar.gz",
    log:
        "results/log/download.log",
    resources:
        runtime=120,
        mem_mb=4000,
    shell:
        "curl -o {output} https://zenodo.org/api/files/c837a57a-6cf8-45a4-bf04-612ee00b63f4/geo-htseq.tar.gz 2> {log}"


rule download_simulation:
    output:
        "results/data/de_simulation_results.csv",
    log:
        "results/log/download.log",
    resources:
        runtime=120,
        mem_mb=4000,
    shell:
        "curl -o {output} https://zenodo.org/record/4463804/files/de_simulation_results.csv?download=1 2> {log}"


rule download_updates:
    output:
        "results/geo-htseq-updates.tar.gz",
    log:
        "results/log/download_updates.log",
    resources:
        runtime=120,
        mem_mb=4000,
    shell:
        "curl -o {output} https://zenodo.org/record/7529832/files/geo-htseq-updates.tar.gz?download=1 2> {log}"


rule unpack:
    input:
        rules.download.output[0],
    output:
        "results/data/document_summaries.csv",
        "results/data/publications.csv",
        "results/data/suppfilenames.txt",
        "results/data/parsed_suppfiles.csv",
        "results/data/scopus_citedbycount.csv",
        "results/data/spots.csv",
        "results/data/suppfilenames_filtered.txt",
        "results/data/cancer.csv",
        "results/data/transcription_factor.csv",
        "results/data/single-cell.csv",
        "results/data/blacklist.txt"
    log:
        "results/log/unpack.log",
    shadow:
        "minimal"
    resources:
        runtime=120,
        mem_mb=4000,
    shell:
        "(tar -xzvf {input} "
        " && mkdir -p $(dirname {output[0]})"
        " && cp output/* $(dirname {output[0]}))"
        " && cp blacklist.txt $(dirname {output[0]})) 2> {log}"


rule unpack_updates:
    input:
        rules.download_updates.output[0],
    output:
        "results/detools_from_pmc.csv",
        "results/n_data.csv",
        "results/simres_df_parsed.csv",
        "results/data/parsed_suppfiles_rerun.csv",
    log:
        "results/log/unpack_updates.log",
    shadow:
        "minimal"
    resources:
        runtime=120,
        mem_mb=4000,
    shell:
        "tar -xzvf {input} 2> {log}"


rule analysis_platform:
    input:
        "results/data/document_summaries.csv",
        "results/detools_from_pmc.csv",
        "results/data/parsed_suppfiles.csv",
    output:
        "results/parse_analysis_platform_output.csv",
    log:
        "results/log/analysis_platform.log",
    resources:
        runtime=120,
        mem_mb=4000,
    script:
        "scripts/parse_analysis_platform.R"

rule preprocess_pvalues:
    input:
        "results/data/document_summaries.csv",
        "results/data/suppfilenames.txt",
        "results/data/parsed_suppfiles.csv",
        "results/parse_analysis_platform_output.csv",
    output:
        "results/pvalues.csv",
        "results/pvalues_sample.csv",
    log:
        "results/log/preprocess_pvalues.log",
    resources:
        runtime=120,
        mem_mb=4000,
    script:
        "scripts/preprocess_pvalues.R"


rule preprocess_pvalues_filtered:
    input:
        "results/data/document_summaries.csv",
        "results/data/parsed_suppfiles.csv",
        "results/pvalues.csv",
    output:
        "results/pvalues_filtered.csv",
    log:
        "results/log/preprocess_pvalues_filtered.log",
    resources:
        runtime=120,
        mem_mb=4000,
    script:
        "scripts/preprocess_pvalues_filtered.R"


rule preprocess_sequence_metadata:
    input:
        "results/data/spots.csv",
    output:
        "results/sequencing_metadata_unique_platform.csv",
        "results/sequencing_metadata.csv",
    log:
        "results/log/preprocess_sequence_metadata.log",
    resources:
        runtime=120,
        mem_mb=4000,
    script:
        "scripts/preprocess_sequence_metadata.R"


rule supporting_information:
    input:
        "results/pvalues.csv",
        "results/pvalues_sample.csv",
        "results/pvalues_filtered.csv",
        "results/sequencing_metadata_unique_platform.csv",
        "results/data/de_simulation_results.csv",
    output:
        "results/supporting_information.pdf",
    log:
        "results/log/supporting_information.log",
    resources:
        runtime=1440,
        mem_mb=8000,
    threads: 4
    shell:
        """
        Rscript -e 'rmarkdown::render(here::here("workflow/scripts/supporting_information.R"), output_dir = here::here("results"))'
        """


rule figures:
    input:
        "results/pvalues.csv",
        "results/pvalues_sample.csv",
        "results/pvalues_filtered.csv",
        "results/data/cancer.csv",
        "results/data/transcription_factor.csv"
        "results/n_data.csv",
        "results/simres_df_parsed.csv",
        "results/data/parsed_suppfiles_rerun.csv",
        "results/sequencing_metadata_unique_platform.csv",
        "results/data/parsed_suppfiles.csv",
        "results/supporting_information.pdf",
    output:
        expand("figures/Fig{n}.{ext}", n=FIGS, ext = "tiff"),
    log:
        "results/log/figures.log",
    resources:
        runtime=1440,
        mem_mb=8000,
    threads: 4
    script:
        "scripts/figures.R"


rule main:
    input:
        expand("figures/Fig{n}.tiff", n=FIGS),
        "results/supporting_information.pdf",
    output:
        "results/main.pdf",
    resources:
        runtime=120,
        mem_mb=8000,
    threads: 4
    shell:
        """
        Rscript -e 'rmarkdown::render(here::here("workflow/scripts/main/main.Rmd"), output_dir = here::here("results"), output_format = "all")'
        """


rule staple:
    input:
        "results/main.pdf",
        "results/supporting_information.pdf",
    output:
        "results/pall_et_al.pdf",
    log:
        "results/log/staple.log",
    resources:
        runtime=120,
        mem_mb=4000,
    threads: 1
    shell:
        "gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/prepress -dNOPAUSE -dQUIET -dBATCH -dDetectDuplicateImages -dCompressFonts=true -r150 -sOutputFile={output[0]} {input} 2> {log}"

